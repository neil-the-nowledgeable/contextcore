# ContextCore Project Context
# This file defines project metadata that Claude Code uses for context-aware assistance
# Updated: 2026-01-21

project:
  id: "contextcore"
  name: "ContextCore"
  epic: "PROJECT-O11Y"
  description: |
    Project management observability framework modeling tasks as OpenTelemetry spans.
    Dual-telemetry architecture: spans to Tempo (hierarchy, timing, TraceQL) and
    structured logs to Loki (events, status changes, metrics derivation via recording rules).

# Current implementation status
status:
  phase: "Phase 4 - OTel GenAI Alignment"
  recentChanges:
    - "Added span-based generation contracts design for proactive LLM truncation prevention"
    - "Enhanced Prime Contractor with validate-before-integrate pattern (fail on truncation)"
    - "Added validate command to Prime Contractor CLI for pre-flight code validation"
    - "Clarified Rabbit (Waabooz) design boundaries—trigger mechanism, NOT communication channel"
    - "Moved workflow.json to core/project-tasks.json—task viewing is Core, not Rabbit"
    - "Updated EXPANSION_PACKS.md with Design Boundaries section"
    - "OTel GenAI semantic convention alignment (dual-emit agent.* + gen_ai.*)"
    - "HistoricalTaskTracker now emits both spans AND logs for demo data"
    - "Exporter supports pushing logs to Loki via push API"
    - "Portfolio dashboard updated with 11 dashboards provisioned (7 core + 4 expansion)"
    - "Dashboard $project variables fixed to default to 'contextcore'"
    - "Identified task tracking vs deliverable validation gap"
    - "Added Fox (Waagosh) alert automation dashboard"
    - "Added Beaver (Amik) lead contractor progress dashboard"
    - "Established Dependency Manifest Pattern for tracking external dependencies"
  nextSteps:
    - "Implement span-based generation contracts in CodeGenerationHandoff class"
    - "Create Code Generation Health dashboard for truncation monitoring"
    - "Verify demo data appears in both Tempo and Loki"
    - "Create agent insights dashboard for gen_ai.* attributes"
    - "Implement Loki recording rules for task_percent_complete metrics"
    - "Add deliverable validation to task completion criteria"
    - "Add CI validation for dependency manifests"
    - "Create pre-commit hook for dependency scanning"

business:
  criticality: critical
  owner: "observability-team"
  value: "Eliminates manual status reporting by deriving project health from artifact metadata"
  costCenter: "platform-engineering"

  risks:
    - risk: "OTLP exporter failure blocks project health reporting"
      priority: P1
      mitigation: "Implement fallback to file-based persistence with async retry"
      scope:
        - "src/contextcore/tracker.py"
        - "src/contextcore/state.py"

    - risk: "Kubernetes controller restart loses in-flight span state"
      priority: P1
      mitigation: "Persist span state to ConfigMap before OTLP export"
      scope:
        - "src/contextcore/state.py"
        - "src/contextcore/detector.py"

    - risk: "Agent insight queries exceed latency budget"
      priority: P2
      mitigation: "Add caching layer with 5-minute TTL for insight queries"
      scope:
        - "src/contextcore/agent/insights.py"

    - risk: "VSCode extension activation delays editor startup"
      priority: P2
      mitigation: "Lazy-load Kubernetes provider, defer context loading"
      scope:
        - "extensions/vscode/**"

    - risk: "Dashboard provisioning fails silently on Grafana API errors"
      priority: P3
      mitigation: "Add retry logic and user-visible error notifications"
      scope:
        - "src/contextcore/dashboards/provisioner.py"

    - risk: "Portfolio dashboard shows no data without both Loki AND Tempo data"
      priority: P2
      mitigation: "Demo generator now emits dual telemetry (spans + logs)"
      scope:
        - "src/contextcore/demo/generator.py"
        - "src/contextcore/demo/exporter.py"

    - risk: "Metrics derivation requires Loki recording rules not yet deployed"
      priority: P2
      mitigation: "Document recording rules in semantic-conventions.md, add provisioning"
      scope:
        - "docs/semantic-conventions.md"
        - "loki/rules/"

    - risk: "Task 'done' status tracks execution, not deliverable completion"
      priority: P2
      mitigation: |
        Task tracking captures workflow execution status (ran successfully) but not
        whether expected deliverables were produced. Add deliverable validation:
        1. Post-completion hooks that verify expected outputs exist
        2. Span events with deliverable checksums or existence checks
        3. Dashboard panels showing tasks vs verified deliverables
      scope:
        - "src/contextcore/tracker.py"
        - "docs/semantic-conventions.md"
      lesson: |
        Discovered via phase tasks that marked 11 tasks as 'done' in Tempo but
        expected document sections were not created. Execution ≠ completion.

    - risk: "Implicit dependencies cause deployment failures"
      priority: P2
      mitigation: |
        Dependencies defined in design artifacts (dashboards, configs) must be
        explicitly declared in manifests and validated at multiple checkpoints:
        1. Dependency manifests at component level (grafana/provisioning/dashboards/dependencies.yaml)
        2. Pre-commit validation for new dependency references
        3. CI pipeline validation of manifest completeness
        4. Runtime verification via contextcore install verify
        See docs/DEPENDENCY_MANIFEST_PATTERN.md for full pattern.
      scope:
        - "grafana/provisioning/dashboards/dependencies.yaml"
        - "docs/DEPENDENCY_MANIFEST_PATTERN.md"
        - "scripts/validate_dependencies.py"
      lesson: |
        Discovered when loading Beaver dashboard that referenced yesoreyeram-infinity-datasource
        plugin not configured in Grafana. Design-time dependencies must flow to deploy-time.
      pattern: "docs/DEPENDENCY_MANIFEST_PATTERN.md"
      antipattern: "Scattered implicit dependencies discovered only at deploy time"

    - risk: "Multiple deployment sources target same namespace causing config drift"
      priority: P2
      mitigation: |
        Consolidate to single source of truth for Kubernetes deployments:
        1. Choose ONE directory as the canonical deployment source
        2. Standardize credentials (passwords, tokens) across all configs
        3. Keep dashboard JSON files in sync between sources
        4. Add CI check that detects divergent deployments
        5. Document which deployment source is authoritative
      scope:
        - "k8s/observability/"
        - "/Users/neilyashinsky/Documents/Deploy/observability/"
      lesson: |
        Discovered two deployment directories targeting same Kind cluster namespace:
        - ContextCore k8s (password: admin, older versions, 8 dashboards)
        - Deploy directory (password: adminadminadmin, newer versions, 6 dashboards)
        Both deploy to 'observability' namespace in 'o11y-dev' Kind cluster.
        Result: Config drift, missing dashboards, authentication confusion.
      antipattern: "Parallel deployment sources with different configs targeting same target"
      pattern: |
        Single Source of Truth: One canonical deployment directory per target environment.
        All other references should import/copy from the source, not maintain parallel configs.
      symptoms:
        - "Dashboard missing after deployment"
        - "Authentication fails with expected password"
        - "Version mismatch between expected and deployed"
        - "Different feature sets depending on which deploy ran last"

    - risk: "Grafana plugin updates not propagating to Kind cluster"
      priority: P2
      mitigation: |
        Docker Desktop's file sharing to Kind nodes can become stale, causing
        plugin code changes to not appear even after rebuild and pod restart.
        Workaround: Manually copy plugin files directly to Kind nodes:
        1. Build plugin: npm run build
        2. Copy to Kind nodes: docker cp module.js NODE:/plugins/contextcore/PLUGIN/
        3. Restart Grafana pod
        See contextcore-owl/CLAUDE.md "Known Issue: Docker Desktop File Sync" for details.
      scope:
        - "contextcore-owl/plugins/**"
        - "contextcore-grafana/grafana/plugins/**"
      lesson: |
        Discovered when workflow panel CORS errors persisted after code fix.
        The plugin source was updated to use /trigger endpoint but Kind nodes
        served stale module.js with old /workflow/dry-run endpoint.
        Root cause: Kind extraMounts use Docker Desktop file sharing which
        doesn't reliably sync file changes to the VM.
      symptoms:
        - "CORS errors from old API endpoints"
        - "Plugin behavior doesn't match source code"
        - "kubectl rollout restart doesn't fix the issue"
        - "grep shows different content in host vs container files"
      antipattern: "Assuming file mounts are live-synced in Kind/Docker Desktop"
      pattern: |
        After plugin rebuild, manually sync to Kind nodes:
        docker cp module.js o11y-dev-worker2:/plugins/contextcore/PLUGIN/module.js

requirements:
  availability: "99.9%"
  latencyP99: "500ms"
  latencyP50: "100ms"
  dataRetention: "30 days"
  throughput: "1000 spans/second"
  errorBudget: "0.1%"

design:
  adr: "docs/adr/001-tasks-as-spans.md"
  doc: "docs/CLAUDE-full.md"
  apiContract: "docs/semantic-conventions.md"
  agentProtocol: "docs/agent-communication-protocol.md"
  otelGenaiMigration: "docs/OTEL_GENAI_MIGRATION_GUIDE.md"
  otelGenaiGapAnalysis: "docs/OTEL_GENAI_GAP_ANALYSIS.md"
  expansionPacks: "docs/EXPANSION_PACKS.md"
  namingConvention: "docs/NAMING_CONVENTION.md"
  dependencyManifest: "docs/DEPENDENCY_MANIFEST_PATTERN.md"

# Expansion Pack Ecosystem
# Animal names with Anishinaabe (Ojibwe) translations honoring Michigan's indigenous peoples
ecosystem:
  namingConvention: "animal-anishinaabe"
  packages:
    - name: "contextcore"
      animal: "Spider"
      anishinaabe: "Asabikeshiinh"
      meaning: "Little net maker"
      purpose: "Core framework—tasks as spans, agent insights, observability"
      status: "beta"
    - name: "contextcore-rabbit"
      animal: "Rabbit"
      anishinaabe: "Waabooz"
      purpose: "Alert-triggered automation—wakes up systems in response to alerts (fire-and-forget)"
      status: "beta"
      formerName: "Hermes"
      designNote: |
        Rabbit is a TRIGGER mechanism, not a communication channel or workflow manager.
        It receives alerts, fires actions, and is done. It does NOT:
        - Serve as a message bus between components
        - Manage ongoing workflows or conversations
        - Coordinate multi-step processes (use Coyote for that)
    - name: "contextcore-fox"
      animal: "Fox"
      anishinaabe: "Waagosh"
      purpose: "ContextCore integration for alert automation (context enrichment)"
      status: "beta"
      dependsOn: ["contextcore-rabbit"]
    - name: "contextcore-coyote"
      animal: "Coyote"
      anishinaabe: "Wiisagi-ma'iingan"
      purpose: "Multi-agent incident resolution pipeline"
      status: "beta"
      formerName: "agent-pipeline"
    - name: "contextcore-beaver"
      animal: "Beaver"
      anishinaabe: "Amik"
      purpose: "LLM provider abstraction with cost tracking and token accounting"
      status: "beta"
      formerName: "startd8"
    - name: "contextcore-squirrel"
      animal: "Squirrel"
      anishinaabe: "Ajidamoo"
      purpose: "Skills library for token-efficient agent discovery and knowledge storage"
      status: "beta"
      formerName: "contextcore-skills"
    - name: "contextcore-owl"
      animal: "Owl"
      anishinaabe: "Gookooko'oo"
      meaning: "Owl (watchful, excellent vision)"
      purpose: "Internal Grafana plugin package (action triggers, chat panels, datasources)"
      status: "internal"  # NOT user-facing
      formerName: "contextcore-grafana"
      dependsOn: ["contextcore-beaver"]  # Optional, for scaffold script LLM generation
      userFacing: false
      designNote: |
        Owl is an INTERNAL sub-component for Grafana plugin development. The name
        "contextcore-owl" is unofficial and should NOT be included in:
        - User documentation or onboarding
        - The "harbor tour" of capabilities
        - Marketing or product descriptions

        Users interact with Grafana dashboards directly—they don't need to know
        about the plugin packaging implementation details.

# Dashboards (11 total, provisioned to Grafana)
# Dependencies declared in: grafana/provisioning/dashboards/dependencies.yaml
dashboards:
  dependencyManifest: "grafana/provisioning/dashboards/dependencies.yaml"
  provisioned:
    # Core dashboards
    - id: "contextcore-portfolio"
      name: "Project Portfolio Overview"
      file: "grafana/provisioning/dashboards/json/portfolio.json"
      datasources: ["Loki", "mimir"]
    - id: "contextcore-installation"
      name: "Installation Verification"
      file: "grafana/provisioning/dashboards/json/installation.json"
      datasources: ["Prometheus/mimir"]
    - id: "contextcore-value"
      name: "Value Capabilities Explorer"
      file: "grafana/provisioning/dashboards/json/value-capabilities.json"
      datasources: ["Tempo"]
    - id: "contextcore-progress"
      name: "Project Progress"
      file: "grafana/provisioning/dashboards/json/project-progress.json"
      datasources: ["Tempo"]
    - id: "contextcore-sprint"
      name: "Sprint Metrics"
      file: "grafana/provisioning/dashboards/json/sprint-metrics.json"
      datasources: ["Tempo"]
    - id: "contextcore-ops"
      name: "Project Operations"
      file: "grafana/provisioning/dashboards/json/project-operations.json"
      datasources: ["Tempo"]
    # Expansion pack dashboards
    - id: "fox-alert-automation"
      name: "Fox Alert Automation"
      file: "grafana/provisioning/dashboards/json/fox-alert-automation.json"
      datasources: ["Tempo", "Loki", "mimir"]
      expansionPack: "contextcore-fox"
    - id: "beaver-lead-contractor"
      name: "Lead Contractor Progress"
      file: "grafana/provisioning/dashboards/json/beaver-lead-contractor-progress.json"
      datasources: ["Tempo", "mimir"]
      expansionPack: "contextcore-beaver"
    - id: "skills-browser"
      name: "Skills Browser"
      file: "grafana/provisioning/dashboards/json/skills-browser.json"
      datasources: ["Tempo"]
      expansionPack: "contextcore-squirrel"
    - id: "contextcore-tasks"
      name: "Project Tasks"
      file: "grafana/provisioning/dashboards/core/project-tasks.json"
      datasources: ["Tempo"]
      # NOTE: This is a CORE dashboard, not a Rabbit dashboard. It shows project tasks
      # stored as spans in Tempo—this is core ContextCore functionality.
      # Rabbit is only for triggering actions, not viewing/managing workflows.
    - id: "agent-trigger"
      name: "Agent Trigger"
      file: "grafana/provisioning/dashboards/json/agent-trigger.json"
      datasources: ["Loki"]
  needed:
    - "Agent Insights Dashboard (gen_ai.* attributes)"
    - "Agent Handoffs Dashboard (handoff.* + gen_ai.tool.*)"

targets:
  - kind: Deployment
    name: contextcore-controller
    namespace: contextcore-system
  - kind: Service
    name: contextcore-api
    namespace: contextcore-system

designDecisions:
  - decision: "Model tasks as OpenTelemetry spans for unified observability"
    confidence: 0.95
    rationale: "Spans have same structure as tasks (start, end, status, hierarchy)"

  - decision: "Export via OTLP for vendor independence"
    confidence: 0.92
    rationale: "Avoid lock-in, works with any OTLP-compatible backend"

  - decision: "Use Pydantic v2 for CRD schema validation"
    confidence: 0.88
    rationale: "Strict validation, good error messages, Python-native"

  - decision: "Store agent insights as spans in Tempo"
    confidence: 0.85
    rationale: "Reuse existing infrastructure, enables time-range queries"

  - decision: "Dual-emit spans (Tempo) AND logs (Loki) for complete observability"
    confidence: 0.90
    rationale: |
      Portfolio dashboard requires both: Tempo for task hierarchy/timing queries,
      Loki for event streams and metrics derivation via recording rules.
      Mimir metrics are derived from Loki logs, not directly emitted.

  - decision: "Align with OTel GenAI semantic conventions via dual-emit"
    confidence: 0.88
    rationale: |
      Emit both agent.* (legacy) and gen_ai.* (OTel standard) attributes during
      migration period. Controlled by CONTEXTCORE_OTEL_MODE env var.
      See docs/OTEL_GENAI_MIGRATION_GUIDE.md for migration path.

  - decision: "Demo generator emits both spans and logs"
    confidence: 0.92
    rationale: |
      HistoricalTaskTracker now uses HistoricalTaskLogger to emit logs with
      historical timestamps alongside spans. Enables full dashboard testing.

  - decision: "Explicit dependency manifests for external dependencies"
    confidence: 0.90
    rationale: |
      Dependencies defined in design artifacts (Grafana plugins in dashboards, external
      APIs in configs) must be explicitly declared in component-level manifests and
      validated at design, build, and deploy time. Prevents "works on my machine" failures.
      See docs/DEPENDENCY_MANIFEST_PATTERN.md for full specification.

  - decision: "Rabbit is a trigger mechanism, not a communication channel"
    confidence: 0.95
    rationale: |
      Rabbit (Waabooz) is designed to "wake up" systems in response to alerts—it is
      NOT a general communication channel, message bus, or workflow orchestration engine.

  - decision: "Span-based generation contracts for proactive LLM truncation prevention"
    confidence: 0.85
    rationale: |
      A2A handoffs for code generation should include size constraints in ExpectedOutput
      (max_lines, max_tokens, completeness_markers). Receiving agents emit pre-flight
      spans with size estimates BEFORE generation. If estimate exceeds limit, decomposition
      is negotiated via span events rather than generating and failing.

      Benefits: Proactive prevention (not reactive validation), auditable decisions via
      TraceQL, graceful degradation via chunking, human visibility via dashboards.

      See docs/A2A_TRUNCATION_PREVENTION.md for full design.

      Rabbit IS:
      - Alert receiver (webhooks from Grafana, Alertmanager)
      - Action dispatcher (fire-and-forget execution)
      - One-way trigger pipeline (alert → action)

      Rabbit IS NOT:
      - Communication bridge between components
      - Workflow manager or orchestrator
      - Bi-directional RPC mechanism
      - Message queue or event bus

      This distinction prevents scope creep and ensures each component serves its purpose.
      For workflow viewing/management, use Core ContextCore dashboards querying Tempo.
      For multi-step pipelines, use Coyote.
    lesson: |
      Previous confusion arose when "workflow" dashboards were attributed to Rabbit.
      The Workflow Manager dashboard displays tasks from Tempo—this is Core ContextCore
      functionality (tasks as spans), not Rabbit functionality (alert triggering).
