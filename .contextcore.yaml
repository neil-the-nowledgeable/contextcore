# ContextCore Project Context
# This file defines project metadata that Claude Code uses for context-aware assistance
# Updated: 2026-02-04

# =============================================================================
# ENVIRONMENT QUICK REFERENCE
# =============================================================================
# Two environments exist until datasets are merged. Use password to identify:
#
#   DEV:  ~/Documents/dev/ContextCore    | password: admin
#   TEST: ~/Documents/Deploy             | password: adminadminadmin
#
# Both target 'observability' namespace in 'o11y-dev' Kind cluster.
# =============================================================================

project:
  id: "contextcore"
  name: "ContextCore"
  epic: "PROJECT-O11Y"
  description: |
    Project management observability framework modeling tasks as OpenTelemetry spans.
    Dual-telemetry architecture: spans to Tempo (hierarchy, timing, TraceQL) and
    structured logs to Loki (events, status changes, metrics derivation via recording rules).

# Current implementation status
status:
  phase: "Phase 4 - OTel GenAI Alignment"
  recentChanges:
    - "Fixed parts.py/part.py module structure corruption from merge process"
    - "Created docs/KNOWN_ISSUES.md troubleshooting guide for common problems"
    - "Fixed multiple import errors in discovery/, generators/ modules"
    - "Documented merge_files_intelligently() as broken (P1 risk) - needs AST rewrite"
    - "Added span-based generation contracts design for proactive LLM truncation prevention"
    - "Enhanced Prime Contractor with validate-before-integrate pattern (fail on truncation)"
    - "Added validate command to Prime Contractor CLI for pre-flight code validation"
    - "Clarified Rabbit (Waabooz) design boundaries—trigger mechanism, NOT communication channel"
    - "Moved workflow.json to core/project-tasks.json—task viewing is Core, not Rabbit"
    - "Updated EXPANSION_PACKS.md with Design Boundaries section"
    - "OTel GenAI semantic convention alignment (dual-emit agent.* + gen_ai.*)"
    - "HistoricalTaskTracker now emits both spans AND logs for demo data"
    - "Exporter supports pushing logs to Loki via push API"
    - "Portfolio dashboard updated with 11 dashboards provisioned (7 core + 4 expansion)"
    - "Dashboard $project variables fixed to default to 'contextcore'"
    - "Identified task tracking vs deliverable validation gap"
    - "Added Fox (Waagosh) alert automation dashboard"
    - "Added Beaver (Amik) lead contractor progress dashboard"
    - "Established Dependency Manifest Pattern for tracking external dependencies"
    - "Created Agent Insights dashboard for gen_ai.* attributes (12 dashboards total)"
    - "Deployed Loki recording rules for task_percent_complete metrics"
    - "Added OTel GenAI dual-emit to startd8-sdk TrackedAgentMixin"
    - "Implemented decomposition logic in CodeGenerationCapability (_decompose_spec, _assemble_chunks, 40 tests)"
    - "Added deliverable validation to TaskTracker (Deliverable dataclass, _validate_deliverables, span events, 20 tests)"
    - "Added load-logs CLI command and fixed Loki exporter dead code bug"
    - "Verified demo data in both Tempo (199 spans) and Loki (862 logs)"
    - "Fixed demo generator timestamp clamping (now - 24h window for --months 0)"
    - "Created scripts/validate_dependencies.py (CI validation for dependency manifests)"
    - "Added .pre-commit-config.yaml with dashboard dependency scanning hook"
    - "Added GitHub Actions workflow for dependency validation on PR"
  nextSteps:
    - "Consolidate DEV and TEST environments into single deployment source"
    - "Add runtime GrafanaPluginRequirement to contextcore install verify"
    - "Create Agent Handoffs dashboard (handoff.* + gen_ai.tool.*)"

business:
  criticality: critical
  owner: "observability-team"
  value: "Eliminates manual status reporting by deriving project health from artifact metadata"
  costCenter: "platform-engineering"

  risks:
    - risk: "OTLP exporter failure blocks project health reporting"
      priority: P1
      mitigation: "Implement fallback to file-based persistence with async retry"
      scope:
        - "src/contextcore/tracker.py"
        - "src/contextcore/state.py"

    - risk: "Kubernetes controller restart loses in-flight span state"
      priority: P1
      mitigation: "Persist span state to ConfigMap before OTLP export"
      scope:
        - "src/contextcore/state.py"
        - "src/contextcore/detector.py"

    - risk: "Agent insight queries exceed latency budget"
      priority: P2
      mitigation: "Add caching layer with 5-minute TTL for insight queries"
      scope:
        - "src/contextcore/agent/insights.py"

    - risk: "VSCode extension activation delays editor startup"
      priority: P2
      mitigation: "Lazy-load Kubernetes provider, defer context loading"
      scope:
        - "extensions/vscode/**"

    - risk: "Dashboard provisioning fails silently on Grafana API errors"
      priority: P3
      mitigation: "Add retry logic and user-visible error notifications"
      scope:
        - "src/contextcore/dashboards/provisioner.py"

    - risk: "Portfolio dashboard shows no data without both Loki AND Tempo data"
      priority: P2
      mitigation: "Demo generator now emits dual telemetry (spans + logs)"
      scope:
        - "src/contextcore/demo/generator.py"
        - "src/contextcore/demo/exporter.py"

    - risk: "Metrics derivation requires Loki recording rules not yet deployed"
      priority: P2
      status: RESOLVED  # Deployed 2026-02-04
      mitigation: |
        **RESOLVED (2026-02-04)**: Loki recording rules deployed.

        loki/rules/fake/contextcore-rules.yaml contains 5 rules across 2 groups:
        - contextcore_task_progress: percent_complete gauge, sprint avg, completed count, progress rate
        - contextcore_task_status: task count by status
        docker-compose.yaml updated with ./loki/rules:/loki/rules:ro volume mount.
      scope:
        - "docs/semantic-conventions.md"
        - "loki/rules/fake/contextcore-rules.yaml"
        - "docker-compose.yaml"

    - risk: "Task 'done' status tracks execution, not deliverable completion"
      priority: P2
      status: RESOLVED  # Fixed 2026-02-04
      mitigation: |
        **RESOLVED (2026-02-04)**: Deliverable validation implemented in TaskTracker.

        start_task() accepts optional deliverables list (Deliverable dataclass: type, path,
        description, validator callable). complete_task() calls _validate_deliverables() which:
        - Calls custom validators or checks os.path.exists() for file types
        - Emits task.deliverables_verified span event with counts and JSON results
        - Sets task.deliverable.count, task.deliverable.verified, task.deliverables_complete attrs
        - Logs warnings for failures but does NOT block completion
        20 new tests + 23 existing pass (43 total).
      scope:
        - "src/contextcore/tracker.py"
        - "docs/semantic-conventions.md"
        - "tests/test_deliverable_validation.py"
      lesson: |
        Discovered via phase tasks that marked 11 tasks as 'done' in Tempo but
        expected document sections were not created. Execution ≠ completion.

    - risk: "Implicit dependencies cause deployment failures"
      priority: P2
      status: MITIGATED  # CI + pre-commit implemented 2026-02-04
      mitigation: |
        **MITIGATED (2026-02-04)**: CI validation and pre-commit hook implemented.

        1. Dependency manifests: grafana/provisioning/dashboards/dependencies.yaml (DONE)
        2. Pre-commit hook: .pre-commit-config.yaml with check-dashboard-dependencies (DONE)
        3. CI pipeline: .github/workflows/validate-dependencies.yml (DONE)
        4. Validation script: scripts/validate_dependencies.py scans 14 dashboards (DONE)
        5. Runtime verification via contextcore install verify (TODO)
        See docs/DEPENDENCY_MANIFEST_PATTERN.md for full pattern.
      scope:
        - "grafana/provisioning/dashboards/dependencies.yaml"
        - "docs/DEPENDENCY_MANIFEST_PATTERN.md"
        - "scripts/validate_dependencies.py"
      lesson: |
        Discovered when loading Beaver dashboard that referenced yesoreyeram-infinity-datasource
        plugin not configured in Grafana. Design-time dependencies must flow to deploy-time.
      pattern: "docs/DEPENDENCY_MANIFEST_PATTERN.md"
      antipattern: "Scattered implicit dependencies discovered only at deploy time"

    - risk: "Multiple deployment sources target same namespace causing config drift"
      priority: P2
      mitigation: |
        Two environments identified - keep separate until merge is complete:

        DEV Environment:
          - Path: .
          - Password: admin
          - Purpose: Development, newer code

        TEST Environment:
          - Path: $DEPLOY_DIR
          - Password: adminadminadmin
          - Purpose: Testing, stable deployments

        Use password as identifier to know which environment you're connected to.
        After merge: Consolidate to single source of truth.
      scope:
        - "k8s/observability/"
        - "$DEPLOY_DIR/observability/"
      lesson: |
        Discovered two deployment directories targeting same Kind cluster namespace:
        - DEV: ContextCore k8s (password: admin)
        - TEST: Deploy directory (password: adminadminadmin)
        Both deploy to 'observability' namespace in 'o11y-dev' Kind cluster.
        Using different passwords as environment identifiers until merge.
      antipattern: "Parallel deployment sources with different configs targeting same target"
      pattern: |
        Single Source of Truth: One canonical deployment directory per target environment.
        All other references should import/copy from the source, not maintain parallel configs.
      symptoms:
        - "Dashboard missing after deployment"
        - "Authentication fails with expected password"
        - "Version mismatch between expected and deployed"
        - "Different feature sets depending on which deploy ran last"

    - risk: "Grafana plugin updates not propagating to Kind cluster"
      priority: P2
      mitigation: |
        Docker Desktop's file sharing to Kind nodes can become stale, causing
        plugin code changes to not appear even after rebuild and pod restart.
        Workaround: Manually copy plugin files directly to Kind nodes:
        1. Build plugin: npm run build
        2. Copy to Kind nodes: docker cp module.js NODE:/plugins/contextcore/PLUGIN/
        3. Restart Grafana pod
        See contextcore-owl/CLAUDE.md "Known Issue: Docker Desktop File Sync" for details.
      scope:
        - "contextcore-owl/plugins/**"
        - "contextcore-grafana/grafana/plugins/**"
      lesson: |
        Discovered when workflow panel CORS errors persisted after code fix.
        The plugin source was updated to use /trigger endpoint but Kind nodes
        served stale module.js with old /workflow/dry-run endpoint.
        Root cause: Kind extraMounts use Docker Desktop file sharing which
        doesn't reliably sync file changes to the VM.
      symptoms:
        - "CORS errors from old API endpoints"
        - "Plugin behavior doesn't match source code"
        - "kubectl rollout restart doesn't fix the issue"
        - "grep shows different content in host vs container files"
      antipattern: "Assuming file mounts are live-synced in Kind/Docker Desktop"
      pattern: |
        After plugin rebuild, manually sync to Kind nodes:
        docker cp module.js o11y-dev-worker2:/plugins/contextcore/PLUGIN/module.js

    - risk: "Prime Contractor merge_files_intelligently() corrupts Python files"
      priority: P1
      status: RESOLVED  # Fixed 2026-01-26
      mitigation: |
        **RESOLVED (2026-01-26)**: AST-based merge implemented in scripts/lead_contractor/ast_merge.py

        The original text-based merge_files_intelligently() function has been replaced with an
        AST-based implementation that correctly handles Python file structure:
        - Decorators preserved with their classes (@dataclass stays attached)
        - Classes topologically sorted by dependency (MessageRole before Message)
        - Imports deduplicated with __future__ first
        - TYPE_CHECKING blocks preserved separately
        - 42 regression tests in tests/test_ast_merge.py

        Feature flag for rollback: export CONTEXTCORE_AST_MERGE=false

        Original problems (now fixed):
        1. Imports scattered throughout file instead of at top
        2. Class definitions mixed with example code
        3. Decorators (@dataclass, @classmethod) separated from their targets
        4. Code placed outside class bodies
        5. Example code from generated files included at module level
      scope:
        - "scripts/lead_contractor/integrate_backlog.py"
        - "src/contextcore/agent/parts.py"
        - "src/contextcore/agent/part.py"
      lesson: |
        Discovered when "0/8 steps" workflow trigger failure traced to syntax errors in parts.py.
        The merge process created "unterminated triple-quoted string literal" and other structural
        corruption. MessageRole class was placed after Message class that referenced it.
        @dataclass decorators were removed. Future imports were moved after other imports.

        Session 2026-01-26: Implemented AST-based merge (scripts/lead_contractor/ast_merge.py)
        that uses Python's ast module for proper structure preservation. Key insight: text-based
        parsing cannot reliably handle decorators, multi-line strings, or class boundaries.
      symptoms:
        - "Workflow Trigger shows 0/N steps and completes in ~2 seconds"
        - "SyntaxError: unterminated triple-quoted string literal"
        - "SyntaxError: from __future__ imports must occur at the beginning"
        - "NameError: name 'X' is not defined (class defined after its use)"
        - "Missing @dataclass or @classmethod decorators"
      antipattern: "String-based Python file merging without AST awareness"
      pattern: |
        AST-based merge workflow (now implemented):
        1. Parse files with ast.parse() to get proper structure
        2. Categorize: imports, classes, functions, constants
        3. Topologically sort classes by dependency
        4. Merge class definitions (add new methods, warn on duplicates)
        5. Generate output with ast.unparse()

        If issues occur, rollback with: export CONTEXTCORE_AST_MERGE=false
      diagnostics: |
        # Run AST merge tests
        python3 -m pytest tests/test_ast_merge.py -v

        # Check for syntax errors
        python3 -m py_compile src/contextcore/agent/parts.py

        # Test imports
        python3 -c "from contextcore.agent.parts import Message, MessageRole"
      documentation: "docs/MERGE_FUNCTION_ISSUES.md"

    - risk: "Generated code contains unguarded example code at module level"
      priority: P2
      mitigation: |
        Generated Python files often include example/demo code at module level that
        executes during import, causing failures like:
        - TypeError: missing required positional arguments (incomplete example instantiation)
        - ImportError: circular imports triggered by example code
        - Runtime errors from example code assumptions

        Prevention:
        - Generated files should use `if __name__ == "__main__":` guards for examples
        - Remove example code sections before integration
        - Rename non-module files to .example extension
      scope:
        - "src/contextcore/discovery/endpoint.py"
        - "src/contextcore/compat/docs_unifiedupdate.py"
        - "generated/**/*_code.py"
      lesson: |
        Discovered when endpoint.py import failed with "AgentCard.__init__() missing 3 required
        positional arguments". The generated file had example code at module level that ran during
        import. Fixed by removing the example code section (lines 193-214).
      symptoms:
        - "TypeError: X.__init__() missing N required positional arguments"
        - "Import fails with runtime error, not syntax error"
        - "Module works when executed directly but fails when imported"
      antipattern: "Unguarded example code in module-level scope"
      pattern: |
        Either remove example code or guard with:
        if __name__ == "__main__":
            # Example code here
      documentation: "docs/KNOWN_ISSUES.md"

requirements:
  availability: "99.9%"
  latencyP99: "500ms"
  latencyP50: "100ms"
  dataRetention: "30 days"
  throughput: "1000 spans/second"
  errorBudget: "0.1%"

design:
  adr: "docs/adr/001-tasks-as-spans.md"
  doc: "docs/CLAUDE-full.md"
  apiContract: "docs/semantic-conventions.md"
  agentProtocol: "docs/agent-communication-protocol.md"
  otelGenaiMigration: "docs/OTEL_GENAI_MIGRATION_GUIDE.md"
  otelGenaiGapAnalysis: "docs/OTEL_GENAI_GAP_ANALYSIS.md"
  expansionPacks: "docs/EXPANSION_PACKS.md"
  namingConvention: "docs/NAMING_CONVENTION.md"
  dependencyManifest: "docs/DEPENDENCY_MANIFEST_PATTERN.md"

# Expansion Pack Ecosystem
# Animal names with Anishinaabe (Ojibwe) translations honoring Michigan's indigenous peoples
ecosystem:
  namingConvention: "animal-anishinaabe"
  packages:
    - name: "contextcore"
      animal: "Spider"
      anishinaabe: "Asabikeshiinh"
      meaning: "Little net maker"
      purpose: "Core framework—tasks as spans, agent insights, observability"
      status: "beta"
    - name: "contextcore-rabbit"
      animal: "Rabbit"
      anishinaabe: "Waabooz"
      purpose: "Alert-triggered automation—wakes up systems in response to alerts (fire-and-forget)"
      status: "beta"
      formerName: "Hermes"
      designNote: |
        Rabbit is a TRIGGER mechanism, not a communication channel or workflow manager.
        It receives alerts, fires actions, and is done. It does NOT:
        - Serve as a message bus between components
        - Manage ongoing workflows or conversations
        - Coordinate multi-step processes (use Coyote for that)
    - name: "contextcore-fox"
      animal: "Fox"
      anishinaabe: "Waagosh"
      purpose: "ContextCore integration for alert automation (context enrichment)"
      status: "implemented"
      implementationPackage: "wayfinder-fox"
      dependsOn: ["contextcore-rabbit"]
    - name: "contextcore-coyote"
      animal: "Coyote"
      anishinaabe: "Wiisagi-ma'iingan"
      purpose: "Multi-agent incident resolution pipeline"
      status: "beta"
      formerName: "agent-pipeline"
    - name: "contextcore-beaver"
      animal: "Beaver"
      anishinaabe: "Amik"
      purpose: "LLM provider abstraction with cost tracking and token accounting"
      status: "beta"
      formerName: "startd8"
    - name: "contextcore-squirrel"
      animal: "Squirrel"
      anishinaabe: "Ajidamoo"
      purpose: "Skills library for token-efficient agent discovery and knowledge storage"
      status: "beta"
      formerName: "contextcore-skills"
    - name: "contextcore-owl"
      animal: "Owl"
      anishinaabe: "Gookooko'oo"
      meaning: "Owl (watchful, excellent vision)"
      purpose: "Internal Grafana plugin package (action triggers, chat panels, datasources)"
      status: "internal"  # NOT user-facing
      formerName: "contextcore-grafana"
      dependsOn: ["contextcore-beaver"]  # Optional, for scaffold script LLM generation
      userFacing: false
      designNote: |
        Owl is an INTERNAL sub-component for Grafana plugin development. The name
        "contextcore-owl" is unofficial and should NOT be included in:
        - User documentation or onboarding
        - The "harbor tour" of capabilities
        - Marketing or product descriptions

        Users interact with Grafana dashboards directly—they don't need to know
        about the plugin packaging implementation details.

# Dashboards (11 total, provisioned to Grafana)
# Dependencies declared in: grafana/provisioning/dashboards/dependencies.yaml
dashboards:
  dependencyManifest: "grafana/provisioning/dashboards/dependencies.yaml"
  provisioned:
    # Core dashboards
    - id: "contextcore-portfolio"
      name: "Project Portfolio Overview"
      file: "grafana/provisioning/dashboards/json/portfolio.json"
      datasources: ["Loki", "mimir"]
    - id: "contextcore-installation"
      name: "Installation Verification"
      file: "grafana/provisioning/dashboards/json/installation.json"
      datasources: ["Prometheus/mimir"]
    - id: "contextcore-value"
      name: "Value Capabilities Explorer"
      file: "grafana/provisioning/dashboards/json/value-capabilities.json"
      datasources: ["Tempo"]
    - id: "contextcore-progress"
      name: "Project Progress"
      file: "grafana/provisioning/dashboards/json/project-progress.json"
      datasources: ["Tempo"]
    - id: "contextcore-sprint"
      name: "Sprint Metrics"
      file: "grafana/provisioning/dashboards/json/sprint-metrics.json"
      datasources: ["Tempo"]
    - id: "contextcore-ops"
      name: "Project Operations"
      file: "grafana/provisioning/dashboards/json/project-operations.json"
      datasources: ["Tempo"]
    # Expansion pack dashboards
    - id: "fox-alert-automation"
      name: "Fox Alert Automation"
      file: "grafana/provisioning/dashboards/json/fox-alert-automation.json"
      datasources: ["Tempo", "Loki", "mimir"]
      expansionPack: "contextcore-fox"
    - id: "beaver-lead-contractor"
      name: "Lead Contractor Progress"
      file: "grafana/provisioning/dashboards/json/beaver-lead-contractor-progress.json"
      datasources: ["Tempo", "mimir"]
      expansionPack: "contextcore-beaver"
    - id: "skills-browser"
      name: "Skills Browser"
      file: "grafana/provisioning/dashboards/json/skills-browser.json"
      datasources: ["Tempo"]
      expansionPack: "contextcore-squirrel"
    - id: "contextcore-tasks"
      name: "Project Tasks"
      file: "grafana/provisioning/dashboards/core/project-tasks.json"
      datasources: ["Tempo"]
      # NOTE: This is a CORE dashboard, not a Rabbit dashboard. It shows project tasks
      # stored as spans in Tempo—this is core ContextCore functionality.
      # Rabbit is only for triggering actions, not viewing/managing workflows.
    - id: "agent-trigger"
      name: "Agent Trigger"
      file: "grafana/provisioning/dashboards/json/agent-trigger.json"
      datasources: ["Loki"]
    - id: "contextcore-agent-insights"
      name: "Agent Insights"
      file: "grafana/provisioning/dashboards/core/agent-insights.json"
      datasources: ["Tempo"]
  needed:
    - "Agent Handoffs Dashboard (handoff.* + gen_ai.tool.*)"

targets:
  - kind: Deployment
    name: contextcore-controller
    namespace: contextcore-system
  - kind: Service
    name: contextcore-api
    namespace: contextcore-system

designDecisions:
  - decision: "Model tasks as OpenTelemetry spans for unified observability"
    confidence: 0.95
    rationale: "Spans have same structure as tasks (start, end, status, hierarchy)"

  - decision: "Export via OTLP for vendor independence"
    confidence: 0.92
    rationale: "Avoid lock-in, works with any OTLP-compatible backend"

  - decision: "Use Pydantic v2 for CRD schema validation"
    confidence: 0.88
    rationale: "Strict validation, good error messages, Python-native"

  - decision: "Store agent insights as spans in Tempo"
    confidence: 0.85
    rationale: "Reuse existing infrastructure, enables time-range queries"

  - decision: "Dual-emit spans (Tempo) AND logs (Loki) for complete observability"
    confidence: 0.90
    rationale: |
      Portfolio dashboard requires both: Tempo for task hierarchy/timing queries,
      Loki for event streams and metrics derivation via recording rules.
      Mimir metrics are derived from Loki logs, not directly emitted.

  - decision: "Align with OTel GenAI semantic conventions via dual-emit"
    confidence: 0.88
    rationale: |
      Emit both agent.* (legacy) and gen_ai.* (OTel standard) attributes during
      migration period. Controlled by CONTEXTCORE_EMIT_MODE env var.
      See docs/OTEL_GENAI_MIGRATION_GUIDE.md for migration path.

  - decision: "Demo generator emits both spans and logs"
    confidence: 0.92
    rationale: |
      HistoricalTaskTracker now uses HistoricalTaskLogger to emit logs with
      historical timestamps alongside spans. Enables full dashboard testing.

  - decision: "Explicit dependency manifests for external dependencies"
    confidence: 0.90
    rationale: |
      Dependencies defined in design artifacts (Grafana plugins in dashboards, external
      APIs in configs) must be explicitly declared in component-level manifests and
      validated at design, build, and deploy time. Prevents "works on my machine" failures.
      See docs/DEPENDENCY_MANIFEST_PATTERN.md for full specification.

  - decision: "Rabbit is a trigger mechanism, not a communication channel"
    confidence: 0.95
    rationale: |
      Rabbit (Waabooz) is designed to "wake up" systems in response to alerts—it is
      NOT a general communication channel, message bus, or workflow orchestration engine.

  - decision: "Span-based generation contracts for proactive LLM truncation prevention"
    confidence: 0.85
    rationale: |
      A2A handoffs for code generation should include size constraints in ExpectedOutput
      (max_lines, max_tokens, completeness_markers). Receiving agents emit pre-flight
      spans with size estimates BEFORE generation. If estimate exceeds limit, decomposition
      is negotiated via span events rather than generating and failing.

      Benefits: Proactive prevention (not reactive validation), auditable decisions via
      TraceQL, graceful degradation via chunking, human visibility via dashboards.

      See docs/A2A_TRUNCATION_PREVENTION.md for full design.

      Rabbit IS:
      - Alert receiver (webhooks from Grafana, Alertmanager)
      - Action dispatcher (fire-and-forget execution)
      - One-way trigger pipeline (alert → action)

      Rabbit IS NOT:
      - Communication bridge between components
      - Workflow manager or orchestrator
      - Bi-directional RPC mechanism
      - Message queue or event bus

      This distinction prevents scope creep and ensures each component serves its purpose.
      For workflow viewing/management, use Core ContextCore dashboards querying Tempo.
      For multi-step pipelines, use Coyote.
    lesson: |
      Previous confusion arose when "workflow" dashboards were attributed to Rabbit.
      The Workflow Manager dashboard displays tasks from Tempo—this is Core ContextCore
      functionality (tasks as spans), not Rabbit functionality (alert triggering).
