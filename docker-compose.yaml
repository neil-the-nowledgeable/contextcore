# ContextCore Observability Stack
#
# Local development stack with persistent storage.
# Data survives container restarts and is stored in ./data/
#
# Usage (macOS/Linux):
#   make up          Start the stack (runs doctor first)
#   make down        Stop (preserve data)
#   make destroy     Delete (auto-backup, confirm)
#   make health      Check component health
#   make smoke-test  Validate entire stack
#
# Usage (Windows PowerShell):
#   .\setup.ps1 up          Start the stack
#   .\setup.ps1 down        Stop (preserve data)
#   .\setup.ps1 health      Check component health
#   .\setup.ps1 smoke-test  Validate entire stack
#
# Or directly with docker compose:
#   docker compose up -d
#   docker compose down      # preserves data
#   docker compose down -v   # destroys data (use make destroy instead)
#
# Windows notes:
#   - Docker Desktop with WSL2 backend is required for bind mount performance.
#   - Hyper-V backend works but bind mounts (./data/*) will be significantly slower.
#   - To check your backend: Docker Desktop > Settings > General > "Use the WSL 2 based engine"

services:
  # ==========================================================================
  # Grafana - Visualization
  # ==========================================================================
  grafana:
    image: grafana/grafana:11.4.0
    container_name: contextcore-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
      - GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS=contextcore-chat-panel,contextcore-workflow-panel,contextcore-datasource
    volumes:
      - ./data/grafana:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./contextcore-owl/grafana/plugins:/var/lib/grafana/plugins:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      tempo:
        condition: service_healthy
      mimir:
        condition: service_healthy
      loki:
        condition: service_healthy
    networks:
      - contextcore

  # ==========================================================================
  # Tempo - Distributed Tracing
  # ==========================================================================
  # Note: OTLP ports (4317/4318) are NOT exposed to host - Alloy is the OTLP ingestion point.
  # Tempo still listens on 4317 internally for Alloy to forward traces to.
  tempo:
    image: grafana/tempo:2.6.1
    container_name: contextcore-tempo
    command: ["-config.file=/etc/tempo/tempo.yaml"]
    ports:
      - "3200:3200"   # Tempo HTTP API (for queries)
      # OTLP ports handled by Alloy - see alloy service below
    volumes:
      - ./data/tempo:/var/tempo
      - ./tempo/tempo.yaml:/etc/tempo/tempo.yaml:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3200/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - contextcore

  # ==========================================================================
  # Mimir - Metrics (Prometheus-compatible)
  # ==========================================================================
  mimir:
    image: grafana/mimir:2.14.1
    container_name: contextcore-mimir
    command: ["-config.file=/etc/mimir/mimir.yaml"]
    ports:
      - "9009:9009"
    volumes:
      - ./data/mimir:/data
      - ./mimir/mimir.yaml:/etc/mimir/mimir.yaml:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9009/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - contextcore

  # ==========================================================================
  # Loki - Log Aggregation
  # ==========================================================================
  loki:
    image: grafana/loki:3.3.2
    container_name: contextcore-loki
    command: ["-config.file=/etc/loki/loki.yaml"]
    ports:
      - "3100:3100"
    volumes:
      - ./data/loki:/loki
      - ./loki/loki.yaml:/etc/loki/loki.yaml:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - contextcore

  # ==========================================================================
  # Alloy - OpenTelemetry Collector (OTLP ingestion point)
  # ==========================================================================
  # Alloy is the SINGLE OTLP ingestion point for all telemetry:
  # - Receives OTLP on 4317 (gRPC) and 4318 (HTTP)
  # - Routes traces to Tempo
  # - Routes metrics to Mimir (via Prometheus remote_write)
  # - Routes logs to Loki
  alloy:
    image: grafana/alloy:v1.5.1
    container_name: contextcore-alloy
    command: ["run", "/etc/alloy/config.docker.alloy", "--server.http.listen-addr=0.0.0.0:12345"]
    ports:
      - "4317:4317"   # OTLP gRPC - primary ingestion endpoint
      - "4318:4318"   # OTLP HTTP
      - "12345:12345" # Alloy UI (for debugging)
    volumes:
      - ./alloy/config.docker.alloy:/etc/alloy/config.docker.alloy:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:12345/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      tempo:
        condition: service_healthy
      mimir:
        condition: service_healthy
      loki:
        condition: service_healthy
    networks:
      - contextcore

networks:
  contextcore:
    driver: bridge
